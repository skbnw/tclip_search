"""
S3ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãƒ»è¡¨ç¤ºWebã‚¢ãƒ—ãƒª

Streamlitã‚’ä½¿ç”¨ã—ã¦ã€S3ãƒã‚±ãƒƒãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚
- æ—¥ä»˜ãƒ»æ™‚é–“ãƒ»æ”¾é€å±€ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
- ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
- ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
- ç”»åƒã®è¡¨ç¤º
"""

import streamlit as st
import boto3
import json
import sys
import os
from typing import Dict, List, Optional
from io import BytesIO
from datetime import date, time, datetime, timedelta

# Windowsç’°å¢ƒã§ã®æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

# S3è¨­å®š
S3_BUCKET_NAME = "tclip-raw-data-2025"
S3_REGION = "ap-northeast-1"
S3_MASTER_PREFIX = "rag/master_text/"
S3_CHUNK_PREFIX = "rag/vector_chunks/"
S3_IMAGE_PREFIX = "rag/images/"

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Tclipãƒ‡ãƒ¼ã‚¿æ¤œç´¢beta",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="collapsed"  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æŠ˜ã‚ŠãŸãŸã‚€
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ” Tclipãƒ‡ãƒ¼ã‚¿æ¤œç´¢beta")
st.markdown("---")

# AWSèªè¨¼æƒ…å ±ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã€Streamlit Secretsã€ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼‰
def get_aws_credentials():
    """AWSèªè¨¼æƒ…å ±ã‚’å–å¾—ï¼ˆå„ªå…ˆé †ä½: Secrets > ç’°å¢ƒå¤‰æ•° > ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼‰"""
    access_key = None
    secret_key = None
    region = S3_REGION
    
    # 1. Streamlit Secretsã‹ã‚‰å–å¾—ï¼ˆStreamlit Cloudã§ä½¿ç”¨ï¼‰
    try:
        if 'AWS_ACCESS_KEY_ID' in st.secrets:
            access_key = st.secrets['AWS_ACCESS_KEY_ID']
            secret_key = st.secrets['AWS_SECRET_ACCESS_KEY']
            region = st.secrets.get('AWS_DEFAULT_REGION', S3_REGION)
            return access_key, secret_key, region
    except (AttributeError, KeyError):
        pass
    
    # 2. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    access_key = os.getenv('AWS_ACCESS_KEY_ID')
    secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
    if access_key and secret_key:
        return access_key, secret_key, os.getenv('AWS_DEFAULT_REGION', S3_REGION)
    
    # 3. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®šï¼‰
    return None, None, None

# AWSèªè¨¼æƒ…å ±ã®å–å¾—
access_key, secret_key, region = get_aws_credentials()

# èªè¨¼æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šï¼ˆboto3ãŒè‡ªå‹•çš„ã«èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ï¼‰
if access_key and secret_key:
    os.environ['AWS_ACCESS_KEY_ID'] = access_key
    os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key
    os.environ['AWS_DEFAULT_REGION'] = region or S3_REGION

@st.cache_resource
def get_s3_client():
    """S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’è‡ªå‹•çš„ã«èª­ã¿è¾¼ã‚€ï¼‰"""
    try:
        # èªè¨¼æƒ…å ±ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        access_key = os.getenv('AWS_ACCESS_KEY_ID')
        secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        region = os.getenv('AWS_DEFAULT_REGION', S3_REGION)
        
        if access_key and secret_key:
            # æ˜ç¤ºçš„ã«èªè¨¼æƒ…å ±ã‚’æ¸¡ã™
            s3_client = boto3.client(
                's3',
                aws_access_key_id=access_key,
                aws_secret_access_key=secret_key,
                region_name=region
            )
        else:
            # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•çš„ã«èª­ã¿è¾¼ã‚€ï¼ˆIAMãƒ­ãƒ¼ãƒ«ãªã©ï¼‰
            s3_client = boto3.client('s3', region_name=region)
        
        return s3_client
    except Exception as e:
        st.error(f"S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # AWSèªè¨¼æƒ…å ±ã®å…¥åŠ›ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    st.subheader("AWSèªè¨¼æƒ…å ±")
    
    # Secretsã‹ã‚‰å–å¾—ã§ããŸã‹ç¢ºèª
    has_secrets = False
    try:
        has_secrets = bool('AWS_ACCESS_KEY_ID' in st.secrets and 'AWS_SECRET_ACCESS_KEY' in st.secrets)
    except (AttributeError, KeyError):
        pass
    
    # ç’°å¢ƒå¤‰æ•°ã«èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    env_has_credentials = bool(os.getenv('AWS_ACCESS_KEY_ID') and os.getenv('AWS_SECRET_ACCESS_KEY'))
    
    # èªè¨¼æƒ…å ±ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
    if has_secrets:
        st.success("âœ… Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    elif env_has_credentials:
        st.info("â„¹ï¸ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    else:
        st.warning("âš ï¸ èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š")
        st.markdown("1. Streamlit Cloud: Settings â†’ Secrets")
        st.markdown("2. ç’°å¢ƒå¤‰æ•°ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºæ™‚ï¼‰")
        st.markdown("3. ä¸‹è¨˜ã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆä¸€æ™‚çš„ï¼‰")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ç”¨ï¼ˆSecretsã‚„ç’°å¢ƒå¤‰æ•°ãŒãªã„å ´åˆï¼‰
    if not has_secrets and not env_has_credentials:
        access_key_id = st.text_input(
            "Access Key ID", 
            value="",
            type="password",
            help="ä¸€æ™‚çš„ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        secret_access_key = st.text_input(
            "Secret Access Key", 
            value="",
            type="password",
            help="ä¸€æ™‚çš„ã«ä½¿ç”¨ã™ã‚‹å ´åˆã¯å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
        
        if access_key_id and secret_access_key:
            # å…¥åŠ›ã•ã‚ŒãŸèªè¨¼æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®š
            os.environ['AWS_ACCESS_KEY_ID'] = access_key_id
            os.environ['AWS_SECRET_ACCESS_KEY'] = secret_access_key
            os.environ['AWS_DEFAULT_REGION'] = S3_REGION
            access_key = access_key_id
            secret_key = secret_access_key
            region = S3_REGION
    
    st.markdown("---")

# S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰è‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ï¼‰
s3_client = get_s3_client()

if s3_client is None:
    st.error("S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚AWSèªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
S3_INDEX_FILE = "rag/search_index/master_index.jsonl"

# ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
@st.cache_data(ttl=3600)  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_search_index(_s3_client) -> List[Dict]:
    """æ¤œç´¢ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ï¼ˆè»½é‡ç‰ˆï¼‰"""
    try:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        response = _s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=S3_INDEX_FILE)
        content = response['Body'].read().decode('utf-8')
        
        index_list = []
        for line in content.strip().split('\n'):
            if line:
                index_list.append(json.loads(line))
        
        return index_list
    except _s3_client.exceptions.NoSuchKey:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å¾“æ¥ã®æ–¹æ³•ã§å–å¾—
        st.warning("âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¾“æ¥ã®æ–¹æ³•ã§ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
        return list_all_master_data_fallback(_s3_client)
    except Exception as e:
        st.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return list_all_master_data_fallback(_s3_client)

@st.cache_data(ttl=3600)  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
def list_all_master_data_fallback(_s3_client) -> List[Dict]:
    """å…¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãªã„å ´åˆï¼‰"""
    try:
        response = _s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=S3_MASTER_PREFIX)
        
        master_list = []
        if 'Contents' in response:
            total_files = len(response['Contents'])
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, obj in enumerate(response['Contents']):
                try:
                    # é€²æ—è¡¨ç¤º
                    if idx % 10 == 0 or idx == total_files - 1:
                        progress = (idx + 1) / total_files
                        progress_bar.progress(progress)
                        status_text.text(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {idx + 1}/{total_files} ãƒ•ã‚¡ã‚¤ãƒ«")
                    
                    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
                    file_response = _s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=obj['Key'])
                    content = file_response['Body'].read().decode('utf-8')
                    lines = content.strip().split('\n')
                    if lines:
                        master_data = json.loads(lines[0])
                        master_list.append(master_data)
                except Exception as e:
                    continue  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
            
            progress_bar.empty()
            status_text.empty()
        
        return master_list
    except Exception as e:
        st.error(f"å…¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€list_all_master_dataã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç‰ˆã«ç½®ãæ›ãˆ
def list_all_master_data(_s3_client) -> List[Dict]:
    """å…¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰"""
    return load_search_index(_s3_client)

# æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ï¼ˆåˆå›ã®ã¿èª­ã¿è¾¼ã¿ï¼‰
@st.cache_data(ttl=3600)  # 1æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_search_options(_s3_client) -> Dict[str, List[str]]:
    """æ¤œç´¢ç”¨ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæ—¥ä»˜ã€æ™‚é–“ã€æ”¾é€å±€ï¼‰ã‚’å–å¾—"""
    try:
        all_masters = list_all_master_data(_s3_client)
        
        dates = set()
        times = set()
        channels = set()
        
        for master in all_masters:
            metadata = master.get('metadata', {})
            
            # æ—¥ä»˜
            if 'date' in metadata:
                date_str = str(metadata['date'])
                if date_str:
                    dates.add(date_str)
            
            # é–‹å§‹æ™‚é–“
            if 'start_time' in metadata:
                start_time = str(metadata['start_time'])
                if start_time:
                    times.add(start_time)
            
            # çµ‚äº†æ™‚é–“
            if 'end_time' in metadata:
                end_time = str(metadata['end_time'])
                if end_time:
                    times.add(end_time)
            
            # æ”¾é€å±€
            if 'channel' in metadata:
                channel = str(metadata['channel'])
                if channel:
                    channels.add(channel)
        
        return {
            'dates': sorted(list(dates)),
            'times': sorted(list(times)),
            'channels': sorted(list(channels))
        }
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {'dates': [], 'times': [], 'channels': []}

# 30åˆ†å˜ä½ã®æ™‚é–“ãƒªã‚¹ãƒˆç”Ÿæˆ
def generate_time_options():
    """30åˆ†å˜ä½ã®æ™‚é–“ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
    times = []
    for hour in range(24):
        for minute in [0, 30]:
            time_obj = time(hour, minute)
            times.append(time_obj)
    return times

# æ™‚é–“ã®è¿‘ä¼¼æ¤œç´¢ï¼ˆ30åˆ†å˜ä½ã§æœ€ã‚‚è¿‘ã„æ™‚é–“ã‚’æ¢ã™ï¼‰
def find_nearest_time(target_time: time, time_list: List[str]) -> Optional[str]:
    """30åˆ†å˜ä½ã§æœ€ã‚‚è¿‘ã„æ™‚é–“ã‚’æ¢ã™"""
    if not target_time or not time_list:
        return None
    
    # æ™‚é–“ã‚’åˆ†ã«å¤‰æ›
    target_minutes = target_time.hour * 60 + target_time.minute
    
    nearest_time = None
    min_diff = float('inf')
    
    for time_str in time_list:
        try:
            # æ™‚é–“æ–‡å­—åˆ—ã‚’è§£æï¼ˆHHMMå½¢å¼ã¾ãŸã¯HH:MMå½¢å¼ï¼‰
            if ':' in time_str:
                parts = time_str.split(':')
                time_minutes = int(parts[0]) * 60 + int(parts[1])
            else:
                if len(time_str) >= 4:
                    time_minutes = int(time_str[:2]) * 60 + int(time_str[2:4])
                else:
                    continue
            
            # 30åˆ†å˜ä½ã«ä¸¸ã‚ã‚‹
            rounded_minutes = round(time_minutes / 30) * 30
            diff = abs(target_minutes - rounded_minutes)
            
            # Â±30åˆ†ä»¥å†…ã‹ãƒã‚§ãƒƒã‚¯
            if diff <= 30 and diff < min_diff:
                min_diff = diff
                nearest_time = time_str
        except (ValueError, IndexError):
            continue
    
    return nearest_time

# æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("search_form"):
    st.subheader("æ¤œç´¢æ¡ä»¶")
    
    # ä¸Šéƒ¨: æ”¾é€å±€ã€æ—¥ä»˜ã€æ™‚é–“
    search_options = get_search_options(_s3_client=s3_client)
    
    # 3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆå‡ç­‰é…ç½®ï¼‰
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        # æ”¾é€å±€ï¼ˆé¸æŠå¼ï¼‰
        channel_options = ["ã™ã¹ã¦"]
        if search_options['channels']:
            channel_options.extend(search_options['channels'])
        else:
            # ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±ãŒãªã„å ´åˆã§ã‚‚è¡¨ç¤º
            st.warning("âš ï¸ æ”¾é€å±€ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        channel = st.selectbox(
            "æ”¾é€å±€",
            options=channel_options,
            help="æ”¾é€å±€ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
    
    with col2:
        # æ—¥ä»˜
        selected_date = st.date_input(
            "ğŸ“† æ—¥ä»˜",
            value=None,
            help="ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰",
            key="date_input"
        )
        date_str = selected_date.strftime("%Y%m%d") if selected_date else None
    
    with col3:
        # æ™‚é–“ï¼ˆ30åˆ†å˜ä½ï¼‰
        time_options = generate_time_options()
        selected_time = st.selectbox(
            "ğŸ• æ™‚é–“",
            options=[None] + time_options,
            format_func=lambda x: x.strftime("%H:%M") if x else "é¸æŠãªã—",
            help="æ™‚é–“ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆ30åˆ†å˜ä½ã€ä»»æ„ï¼‰",
            key="time_input"
        )
        time_str = selected_time.strftime("%H%M") if selected_time else None
    
    st.markdown("---")
    
    # ä¸‹éƒ¨: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    keyword = st.text_input(
        "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå…¨æ–‡ãƒ»ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ï¼‰",
        placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰",
        help="å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¤œç´¢ã—ã¾ã™"
    )
    
    # æ¤œç´¢ãƒœã‚¿ãƒ³
    search_button = st.form_submit_button("ğŸ” æ¤œç´¢", use_container_width=True)
    
    # program_idã¯å‰Šé™¤ï¼ˆä½¿ç”¨ã—ãªã„ï¼‰
    program_id = ""

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–ï¼ˆè©³ç´°è¡¨ç¤ºç”¨ï¼‰
if 'selected_doc_id' not in st.session_state:
    st.session_state.selected_doc_id = None
if 'search_results' not in st.session_state:
    st.session_state.search_results = []

# ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°
@st.cache_data(ttl=300)  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_master_data(_s3_client, doc_id: str) -> Optional[Dict]:
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        key = f"{S3_MASTER_PREFIX}{doc_id}.jsonl"
        response = _s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=key)
        content = response['Body'].read().decode('utf-8')
        
        # JSON Lineså½¢å¼ãªã®ã§ã€æœ€åˆã®è¡Œã‚’èª­ã¿è¾¼ã‚€
        lines = content.strip().split('\n')
        if lines:
            return json.loads(lines[0])
        return None
    except _s3_client.exceptions.NoSuchKey:
        return None
    except Exception as e:
        st.error(f"ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

@st.cache_data(ttl=300)
def get_chunk_data(_s3_client, doc_id: str) -> List[Dict]:
    """ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        key = f"{S3_CHUNK_PREFIX}{doc_id}_segments.jsonl"
        response = _s3_client.get_object(Bucket=S3_BUCKET_NAME, Key=key)
        content = response['Body'].read().decode('utf-8')
        
        chunks = []
        for line in content.strip().split('\n'):
            if line:
                chunks.append(json.loads(line))
        return chunks
    except _s3_client.exceptions.NoSuchKey:
        return []
    except Exception as e:
        st.error(f"ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

@st.cache_data(ttl=300)
def list_images(_s3_client, doc_id: str) -> List[str]:
    """ç”»åƒURLã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    try:
        prefix = f"{S3_IMAGE_PREFIX}{doc_id}/"
        response = _s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=prefix)
        
        image_urls = []
        if 'Contents' in response:
            for obj in response['Contents']:
                key = obj['Key']
                if key.endswith(('.jpeg', '.jpg', '.png')):
                    # ç½²åä»˜ãURLã‚’ç”Ÿæˆï¼ˆ1æ™‚é–“æœ‰åŠ¹ï¼‰
                    url = _s3_client.generate_presigned_url(
                        'get_object',
                        Params={'Bucket': S3_BUCKET_NAME, 'Key': key},
                        ExpiresIn=3600
                    )
                    image_urls.append(url)
        return image_urls
    except Exception as e:
        st.error(f"ç”»åƒä¸€è¦§ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []


def search_master_data_advanced(
    master_list: List[Dict], 
    program_id: str = "",
    date_str: str = "",
    time_str: str = "",
    channel: str = "",
    keyword: str = "",
    time_tolerance_minutes: int = 30
) -> List[Dict]:
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°æ¡ä»¶ã§æ¤œç´¢ï¼ˆæ™‚é–“è¿‘ä¼¼æ¤œç´¢å¯¾å¿œï¼‰"""
    results = []
    
    for master in master_list:
        metadata = master.get('metadata', {})
        doc_id = master.get('doc_id', '')
        
        # å„æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        match = True
        
        # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿
        if date_str:
            master_date = str(metadata.get('date', ''))
            # æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›ã—ã¦æ¯”è¼ƒï¼ˆYYYYMMDDå½¢å¼ï¼‰
            if date_str not in master_date:
                match = False
                continue
        
        # æ™‚é–“ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆè¿‘ä¼¼æ¤œç´¢ï¼‰
        if time_str:
            start_time = str(metadata.get('start_time', ''))
            end_time = str(metadata.get('end_time', ''))
            
            # ç›®æ¨™æ™‚é–“ã‚’åˆ†ã«å¤‰æ›
            try:
                target_hour = int(time_str[:2])
                target_minute = int(time_str[2:4])
                target_minutes = target_hour * 60 + target_minute
            except (ValueError, IndexError):
                match = False
                continue
            
            # é–‹å§‹æ™‚é–“ã¨çµ‚äº†æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
            time_match = False
            
            # é–‹å§‹æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
            if start_time:
                try:
                    if ':' in start_time:
                        parts = start_time.split(':')
                        start_minutes = int(parts[0]) * 60 + int(parts[1])
                    else:
                        if len(start_time) >= 4:
                            start_minutes = int(start_time[:2]) * 60 + int(start_time[2:4])
                        else:
                            start_minutes = None
                    
                    if start_minutes is not None:
                        diff = abs(target_minutes - start_minutes)
                        if diff <= time_tolerance_minutes:
                            time_match = True
                except (ValueError, IndexError):
                    pass
            
            # çµ‚äº†æ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
            if not time_match and end_time:
                try:
                    if ':' in end_time:
                        parts = end_time.split(':')
                        end_minutes = int(parts[0]) * 60 + int(parts[1])
                    else:
                        if len(end_time) >= 4:
                            end_minutes = int(end_time[:2]) * 60 + int(end_time[2:4])
                        else:
                            end_minutes = None
                    
                    if end_minutes is not None:
                        diff = abs(target_minutes - end_minutes)
                        if diff <= time_tolerance_minutes:
                            time_match = True
                except (ValueError, IndexError):
                    pass
            
            if not time_match:
                match = False
                continue
        
        # æ”¾é€å±€ã§ãƒ•ã‚£ãƒ«ã‚¿
        if channel and channel != "ã™ã¹ã¦":
            master_channel = str(metadata.get('channel', ''))
            if channel not in master_channel:
                match = False
                continue
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå…¨æ–‡ã¨ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆï¼‰
        if keyword and keyword.strip():
            keyword_lower = keyword.strip().lower()
            full_text = master.get('full_text', '').lower()
            if keyword_lower not in full_text:
                match = False
                continue
        
        if match:
            results.append(master)
    
    return results

def search_master_data_with_chunks(
    _s3_client,
    master_list: List[Dict], 
    program_id: str = "",
    date_str: str = "",
    time_str: str = "",
    channel: str = "",
    keyword: str = "",
    time_tolerance_minutes: int = 30,
    max_results: int = 500  # æ¤œç´¢çµæœã®ä¸Šé™ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
) -> List[Dict]:
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€è©³ç´°æ¤œç´¢ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    # ã¾ãšåŸºæœ¬æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§é«˜é€Ÿï¼‰
    filtered_masters = search_master_data_advanced(
        master_list, program_id, date_str, time_str, channel, "", time_tolerance_minutes
    )
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if keyword and keyword.strip():
        keyword_lower = keyword.strip().lower()
        results = []
        
        # é€²æ—è¡¨ç¤ºç”¨
        total = len(filtered_masters)
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å…¨æ–‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚é«˜é€Ÿï¼‰
        for idx, master in enumerate(filtered_masters):
            # æ¤œç´¢çµæœã®ä¸Šé™ã«é”ã—ãŸã‚‰çµ‚äº†
            if len(results) >= max_results:
                status_text.text(f"æ¤œç´¢å®Œäº†: {len(results)} ä»¶ï¼ˆä¸Šé™ã«é”ã—ã¾ã—ãŸï¼‰")
                break
            
            # é€²æ—è¡¨ç¤ºï¼ˆ50ä»¶ã”ã¨ã€å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜é€Ÿã«ï¼‰
            if idx % 50 == 0 or idx == total - 1:
                progress = (idx + 1) / total
                progress_bar.progress(progress)
                status_text.text(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ä¸­: {idx + 1}/{total} ä»¶ï¼ˆ{len(results)} ä»¶ãƒ’ãƒƒãƒˆï¼‰")
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹
            full_text = master.get('full_text', '').lower()
            
            if keyword_lower in full_text:
                results.append(master)
        
        # ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å…¨æ–‡ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ä¸è¦ï¼‰
        # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã§ååˆ†é«˜é€Ÿã«æ¤œç´¢å¯èƒ½
        
        progress_bar.empty()
        status_text.empty()
        
        # æ¤œç´¢çµæœãŒä¸Šé™ã«é”ã—ãŸå ´åˆã®è­¦å‘Š
        if len(results) >= max_results:
            st.info(f"â„¹ï¸ æ¤œç´¢çµæœãŒ{max_results}ä»¶ã«é”ã—ãŸãŸã‚ã€è¡¨ç¤ºã‚’åˆ¶é™ã—ã¾ã—ãŸã€‚æ¤œç´¢æ¡ä»¶ã‚’çµã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚")
        
        return results
    
    return filtered_masters

def display_master_data(master_data, chunks, images, doc_id):
    """ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã€ãƒãƒ£ãƒ³ã‚¯ã€ç”»åƒã‚’è¡¨ç¤º"""
    if not master_data:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
    metadata = master_data.get('metadata', {})
    
    # ã‚¿ãƒ–ã§è¡¨ç¤ºï¼ˆç•ªçµ„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ç”»åƒã€å…¨æ–‡ã€ãƒãƒ£ãƒ³ã‚¯ï¼‰
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ ç•ªçµ„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿", "ğŸ–¼ï¸ ç”»åƒ", "ğŸ“„ å…¨æ–‡", "ğŸ“‘ ãƒãƒ£ãƒ³ã‚¯"])
    
    with tab1:
        st.subheader("ç•ªçµ„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿")
        
        # ãƒ¡ã‚¿æƒ…å ±ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        if metadata:
            # ä¸»è¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
            table_data = []
            
            # åŸºæœ¬æƒ…å ±
            if metadata.get('event_id'):
                table_data.append({"é …ç›®": "ã‚¤ãƒ™ãƒ³ãƒˆID", "å€¤": metadata.get('event_id')})
            if metadata.get('channel_code'):
                table_data.append({"é …ç›®": "ãƒãƒ£ãƒ³ãƒãƒ«ã‚³ãƒ¼ãƒ‰", "å€¤": metadata.get('channel_code')})
            if metadata.get('channel'):
                table_data.append({"é …ç›®": "æ”¾é€å±€", "å€¤": metadata.get('channel')})
            if metadata.get('region'):
                table_data.append({"é …ç›®": "åœ°åŸŸ", "å€¤": metadata.get('region')})
            
            # æ—¥æ™‚æƒ…å ±
            if metadata.get('date') or metadata.get('broadcast_date'):
                date_val = metadata.get('broadcast_date') or metadata.get('date')
                table_data.append({"é …ç›®": "æ”¾é€æ—¥", "å€¤": format_date_display_detail(str(date_val))})
            if metadata.get('start_time'):
                start_time = format_time_display_detail(metadata.get('start_time', ''))
                table_data.append({"é …ç›®": "é–‹å§‹æ™‚é–“", "å€¤": start_time})
            if metadata.get('end_time'):
                end_time = format_time_display_detail(metadata.get('end_time', ''))
                table_data.append({"é …ç›®": "çµ‚äº†æ™‚é–“", "å€¤": end_time})
            
            # ç•ªçµ„æƒ…å ±
            if metadata.get('program_name') or metadata.get('program_title') or metadata.get('master_title'):
                program_name = metadata.get('program_name') or metadata.get('program_title') or metadata.get('master_title')
                table_data.append({"é …ç›®": "ç•ªçµ„å", "å€¤": program_name})
            if metadata.get('program_detail'):
                table_data.append({"é …ç›®": "ç•ªçµ„è©³ç´°", "å€¤": metadata.get('program_detail')})
            if metadata.get('description'):
                table_data.append({"é …ç›®": "èª¬æ˜", "å€¤": metadata.get('description')})
            if metadata.get('description_detail'):
                table_data.append({"é …ç›®": "è©³ç´°èª¬æ˜", "å€¤": metadata.get('description_detail')})
            if metadata.get('genre'):
                table_data.append({"é …ç›®": "ã‚¸ãƒ£ãƒ³ãƒ«", "å€¤": metadata.get('genre')})
            
            # ãƒªãƒ³ã‚¯æƒ…å ±
            if metadata.get('link'):
                table_data.append({"é …ç›®": "ãƒªãƒ³ã‚¯", "å€¤": f"[{metadata.get('link')}]({metadata.get('link')})"})
            if metadata.get('official_website'):
                table_data.append({"é …ç›®": "å…¬å¼ã‚µã‚¤ãƒˆ", "å€¤": f"[{metadata.get('official_website')}]({metadata.get('official_website')})"})
            
            # å‡ºæ¼”è€…æƒ…å ±
            if metadata.get('talents'):
                talents = metadata.get('talents', [])
                if isinstance(talents, list) and len(talents) > 0:
                    talent_names = []
                    for talent in talents:
                        if isinstance(talent, dict):
                            name = talent.get('name', '')
                            if name:
                                talent_names.append(name)
                        elif isinstance(talent, str):
                            talent_names.append(talent)
                    if talent_names:
                        table_data.append({"é …ç›®": "å‡ºæ¼”è€…", "å€¤": ", ".join(talent_names)})
            if metadata.get('talent_count'):
                table_data.append({"é …ç›®": "å‡ºæ¼”è€…æ•°", "å€¤": str(metadata.get('talent_count'))})
            
            # ãã®ä»–ã®æƒ…å ±
            if metadata.get('data_source'):
                table_data.append({"é …ç›®": "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "å€¤": metadata.get('data_source')})
            if metadata.get('metadata_generated_at'):
                table_data.append({"é …ç›®": "ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ—¥æ™‚", "å€¤": metadata.get('metadata_generated_at')})
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            if table_data:
                st.markdown("### åŸºæœ¬æƒ…å ±")
                # HTMLãƒ†ãƒ¼ãƒ–ãƒ«é¢¨ã®è¡¨ç¤º
                for row in table_data:
                    col1, col2 = st.columns([2, 5])
                    with col1:
                        st.markdown(f"**{row['é …ç›®']}**")
                    with col2:
                        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒªãƒ³ã‚¯ã‚’å‡¦ç†
                        if row['å€¤'].startswith('[') and '](' in row['å€¤']:
                            st.markdown(row['å€¤'])
                        else:
                            st.markdown(row['å€¤'])
                    st.markdown("---")
            else:
                st.info("è¡¨ç¤ºå¯èƒ½ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
            # å…¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ã‚‚è¡¨ç¤ºï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
            with st.expander("ğŸ“‹ å…¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰", expanded=False):
                st.json(metadata)
        else:
            st.info("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab2:
        st.subheader("ç”»åƒ")
        if images:
            st.info(f"ç”»åƒæ•°: {len(images)}")
            # ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºï¼ˆ3åˆ—ï¼‰
            cols = st.columns(3)
            for idx, img_url in enumerate(images):
                with cols[idx % 3]:
                    try:
                        st.image(img_url, caption=f"ç”»åƒ {idx+1}", use_container_width=True)
                    except Exception as e:
                        st.error(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.info("ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab3:
        st.subheader("å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ")
        if 'full_text' in master_data and master_data['full_text']:
            st.text_area("", value=master_data['full_text'], height=400, key=f"full_text_{doc_id}")
        else:
            st.info("å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
    
    with tab4:
        st.subheader("ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿")
        if chunks:
            # ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
            chunk_keyword = st.text_input(
                "ãƒãƒ£ãƒ³ã‚¯å†…æ¤œç´¢",
                key=f"chunk_search_{doc_id}",
                placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            )
            
            filtered_chunks = chunks
            if chunk_keyword:
                keyword_lower = chunk_keyword.lower()
                filtered_chunks = [chunk for chunk in chunks if keyword_lower in chunk.get('text', '').lower()]
            
            st.info(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)} (è¡¨ç¤º: {len(filtered_chunks)})")
            
            for idx, chunk in enumerate(filtered_chunks):
                with st.expander(f"ãƒãƒ£ãƒ³ã‚¯ {idx+1}", expanded=False):
                    st.write(chunk.get('text', ''))
                    if 'metadata' in chunk:
                        st.json(chunk['metadata'])
        else:
            st.info("ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

# è©³ç´°è¡¨ç¤ºç”¨ã®æ™‚é–“ãƒ»æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé–¢æ•°
def format_time_display_detail(time_str):
    """æ™‚é–“å½¢å¼ã‚’å¤‰æ›ï¼ˆè©³ç´°è¡¨ç¤ºç”¨ï¼‰"""
    if not time_str or str(time_str).strip() == '':
        return ''
    try:
        time_str = str(time_str)
        # YYYYMMDDHHMMå½¢å¼ã®å ´åˆ
        if len(time_str) >= 12:
            hour = time_str[8:10]
            minute = time_str[10:12]
            return f"{hour}:{minute}"
        # HHMMå½¢å¼ã®å ´åˆ
        elif len(time_str) >= 4:
            hour = time_str[:2]
            minute = time_str[2:4]
            return f"{hour}:{minute}"
        # HH:MMå½¢å¼ã®å ´åˆ
        elif ':' in time_str:
            return time_str
        else:
            return time_str
    except Exception:
        return ''

def format_date_display_detail(date_str):
    """æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›ï¼ˆè©³ç´°è¡¨ç¤ºç”¨ï¼‰"""
    if not date_str or str(date_str).strip() == '':
        return ''
    try:
        date_str = str(date_str)
        # YYYYMMDDå½¢å¼ã®å ´åˆ
        if len(date_str) >= 8 and date_str.isdigit():
            return f"{date_str[:4]}/{date_str[4:6]}/{date_str[6:8]}"
        else:
            return date_str
    except Exception:
        return ''

# æ¤œç´¢å®Ÿè¡Œ
if search_button:
    # æ¤œç´¢æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã ã‘ã§ã‚‚æ¤œç´¢å¯èƒ½ï¼‰
    if not date_str and not time_str and (not channel or channel == "ã™ã¹ã¦") and not keyword:
        st.warning("âš ï¸ æ¤œç´¢æ¡ä»¶ã‚’1ã¤ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œç´¢ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ´»ç”¨ï¼‰
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...ï¼ˆåˆå›ã®ã¿æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
            all_masters = list_all_master_data(_s3_client=s3_client)
        
        if not all_masters:
            st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        else:
            # æ¤œç´¢æ¡ä»¶ã®è¡¨ç¤º
            search_conditions = []
            if date_str:
                search_conditions.append(f"æ—¥ä»˜: {selected_date.strftime('%Yå¹´%mæœˆ%dæ—¥') if selected_date else date_str}")
            if time_str:
                search_conditions.append(f"æ™‚é–“: {selected_time.strftime('%H:%M') if selected_time else time_str}")
            if channel and channel != "ã™ã¹ã¦":
                search_conditions.append(f"æ”¾é€å±€: {channel}")
            if keyword:
                search_conditions.append(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
            
            with st.spinner(f"æ¤œç´¢ä¸­: {', '.join(search_conditions) if search_conditions else 'æ¡ä»¶ãªã—'}..."):
                search_results = search_master_data_with_chunks(
                    _s3_client=s3_client,
                    master_list=all_masters,
                    program_id="",  # ç•ªçµ„IDã¯å‰Šé™¤
                    date_str=date_str if date_str else "",
                    time_str=time_str if time_str else "",
                    channel=channel if channel != "ã™ã¹ã¦" else "",
                    keyword=keyword,
                    time_tolerance_minutes=30  # 30åˆ†ä»¥å†…ã®è¿‘ä¼¼æ¤œç´¢
                )
            
            # æ¤œç´¢çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state.search_results = search_results
            
            if not search_results:
                st.warning("âš ï¸ æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.success(f"âœ… {len(search_results)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                st.markdown("---")

# æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆè¡¨ç¤ºï¼ˆè©³ç´°è¡¨ç¤ºå‰ã«ï¼‰
if st.session_state.search_results:
    st.subheader("ğŸ“‹ æ¤œç´¢çµæœ")
    
    # è©³ç´°è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼ˆç‹¬ç«‹ã—ãŸç”»é¢ã¨ã—ã¦è¡¨ç¤ºï¼‰
    if st.session_state.selected_doc_id:
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³ã¨ã‚¿ã‚¤ãƒˆãƒ«
        col_back, col_title = st.columns([1, 9])
        with col_back:
            if st.button("â† æˆ»ã‚‹", use_container_width=True):
                st.session_state.selected_doc_id = None
                st.rerun()
        with col_title:
            st.markdown("### ğŸ“„ è©³ç´°æƒ…å ±")
        st.markdown("---")
        doc_id = st.session_state.selected_doc_id
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
            full_master_data = get_master_data(_s3_client=s3_client, doc_id=doc_id)
            chunks = get_chunk_data(_s3_client=s3_client, doc_id=doc_id)
            images = list_images(_s3_client=s3_client, doc_id=doc_id)
        
        display_master_data(full_master_data, chunks, images, doc_id)
    
    # ãƒªã‚¹ãƒˆè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
    else:
        # æ™‚é–“å½¢å¼ã‚’å¤‰æ›ã™ã‚‹é–¢æ•°
        def format_time_display(time_str):
            """æ™‚é–“å½¢å¼ã‚’å¤‰æ›ï¼ˆYYYYMMDDHHMM -> HH:MMï¼‰"""
            if not time_str or time_str == 'N/A' or str(time_str).strip() == '':
                return ''
            try:
                time_str = str(time_str)
                # YYYYMMDDHHMMå½¢å¼ã®å ´åˆ
                if len(time_str) >= 12:
                    hour = time_str[8:10]
                    minute = time_str[10:12]
                    return f"{hour}:{minute}"
                # HHMMå½¢å¼ã®å ´åˆ
                elif len(time_str) >= 4:
                    hour = time_str[:2]
                    minute = time_str[2:4]
                    return f"{hour}:{minute}"
                # HH:MMå½¢å¼ã®å ´åˆ
                elif ':' in time_str:
                    return time_str
                else:
                    return time_str
            except Exception:
                return ''
        
        # æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›ã™ã‚‹é–¢æ•°
        def format_date_display(date_str):
            """æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›ï¼ˆYYYYMMDD -> YYYY/MM/DDï¼‰"""
            if not date_str or date_str == 'N/A' or str(date_str).strip() == '':
                return ''
            try:
                date_str = str(date_str)
                # YYYYMMDDå½¢å¼ã®å ´åˆ
                if len(date_str) >= 8 and date_str.isdigit():
                    return f"{date_str[:4]}/{date_str[4:6]}/{date_str[6:8]}"
                else:
                    return date_str
            except Exception:
                return ''
        
        # çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
        results_data = []
        for idx, master in enumerate(st.session_state.search_results):
            doc_id = master.get('doc_id', '')
            metadata = master.get('metadata', {})
            
            # æ”¾é€æ—¥æ™‚ãƒ»æ™‚é–“
            date_str = metadata.get('date', '')
            start_time = metadata.get('start_time', '')
            end_time = metadata.get('end_time', '')
            
            # æ™‚é–“å½¢å¼ã‚’å¤‰æ›
            start_time_display = format_time_display(str(start_time)) if start_time else ''
            end_time_display = format_time_display(str(end_time)) if end_time else ''
            
            # æ™‚é–“ç¯„å›²ã®è¡¨ç¤º
            if start_time_display and end_time_display:
                time_range = f"{start_time_display} - {end_time_display}"
            elif start_time_display:
                time_range = start_time_display
            elif end_time_display:
                time_range = end_time_display
            else:
                time_range = ''
            
            # æ—¥ä»˜å½¢å¼ã‚’å¤‰æ›
            date_display = format_date_display(str(date_str)) if date_str else ''
            
            # æ”¾é€å±€
            channel = str(metadata.get('channel', '')) if metadata.get('channel') else ''
            
            # ç•ªçµ„å
            program_name = str(metadata.get('program_name', metadata.get('title', ''))) if metadata.get('program_name') or metadata.get('title') else ''
            if len(program_name) > 20:
                program_name = program_name[:20] + "..."
            
            results_data.append({
                'No.': idx + 1,
                'æ”¾é€æ—¥æ™‚': date_display,
                'æ™‚é–“': time_range,
                'æ”¾é€å±€': channel,
                'ç•ªçµ„å': program_name,
                'doc_id': doc_id
            })
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹ãŸã‚ã«ã‚«ã‚¹ã‚¿ãƒ è¡¨ç¤ºï¼‰
        for idx, row in enumerate(results_data):
            with st.container():
                # ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
                col1, col2, col3, col4, col5, col6 = st.columns([0.3, 1.2, 1.5, 1.5, 2, 0.8])
                
                with col1:
                    st.write(f"**{row['No.']}**")
                
                with col2:
                    st.write(f"ğŸ“… {row['æ”¾é€æ—¥æ™‚']}")
                
                with col3:
                    st.write(f"ğŸ• {row['æ™‚é–“']}")
                
                with col4:
                    st.write(f"ğŸ“º {row['æ”¾é€å±€']}")
                
                with col5:
                    st.write(f"ğŸ“º {row['ç•ªçµ„å']}")
                
                with col6:
                    # è©³ç´°ãƒœã‚¿ãƒ³ï¼ˆæ–°ã—ã„ã‚¿ãƒ–ã§é–‹ããƒªãƒ³ã‚¯é¢¨ï¼‰
                    if st.button(f"è©³ç´°", key=f"detail_{row['doc_id']}", use_container_width=True):
                        st.session_state.selected_doc_id = row['doc_id']
                        st.rerun()
                
                st.markdown("---")

else:
    # åˆæœŸçŠ¶æ…‹ã®èª¬æ˜
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§AWSèªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã€æ¤œç´¢æ¡ä»¶ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    st.markdown("""
    ## ğŸ“– ä½¿ã„æ–¹
    
    1. **æ¤œç´¢æ¡ä»¶ã‚’å…¥åŠ›**
       - æ”¾é€å±€ã€æ—¥ä»˜ã€æ™‚é–“ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰é¸æŠ
       - ã™ã¹ã¦ä»»æ„é …ç›®ã§ã™ï¼ˆ1ã¤ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ï¼‰
    
    2. **æ¤œç´¢çµæœã‚’ç¢ºèª**
       - æ¤œç´¢çµæœãŒãƒªã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤ºã•ã‚Œã¾ã™
       - ã€Œè©³ç´°ã‚’è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    
    3. **è©³ç´°æƒ…å ±ã®é–²è¦§**
       - å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã€ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã€ç”»åƒã‚’ç¢ºèªã§ãã¾ã™
    
    ---
    
    ## âš ï¸ ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã«ã¤ã„ã¦
    
    **ç¾åœ¨æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿æœŸé–“**: 2025å¹´10æœˆ3æ—¥ ï½ 2025å¹´10æœˆ26æ—¥
    
    ã“ã®æœŸé–“å¤–ã®æ—¥ä»˜ã§æ¤œç´¢ã—ãŸå ´åˆã€æ¤œç´¢çµæœãŒè¡¨ç¤ºã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
    """)
